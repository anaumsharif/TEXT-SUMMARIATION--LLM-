{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMn0fObXRypd5HTFrTzWdpK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5otcuTdNGKaY","executionInfo":{"status":"ok","timestamp":1708277897419,"user_tz":-330,"elapsed":4,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"outputs":[],"source":["import os\n","open_api_key=\"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\"\n","os.environ[\"OPENAI_API_KEY\"]=open_api_key"]},{"cell_type":"code","source":["! pip install langchain"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJSmaevKUixh","executionInfo":{"status":"ok","timestamp":1708277911722,"user_tz":-330,"elapsed":14306,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"5ed95905-6eb6-42dc-d060-bb3e168af668"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain\n","  Downloading langchain-0.1.7-py3-none-any.whl (815 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.9/815.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langchain-community<0.1,>=0.0.20 (from langchain)\n","  Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.2,>=0.1.22 (from langchain)\n","  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n","  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.1)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (3.7.1)\n","Collecting langsmith<0.1,>=0.0.83 (from langchain)\n","  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.2)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.2.0)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n","Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.7 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","source":["## Basic Prompt Summarization\n","from langchain.chat_models import ChatOpenAI\n","from langchain.schema import(\n","    AIMessage,\n","    HumanMessage,\n","    SystemMessage\n",")"],"metadata":{"id":"S9shzHyhUfL5","executionInfo":{"status":"ok","timestamp":1708277912924,"user_tz":-330,"elapsed":1207,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["abstract=\"\"\"\n","Computer vision is an area of research concerned\n","with assisting computers in seeing. Computer vision issues aim\n","to infer something about the world from observed picture data\n","at the most abstract level. It is a multidisciplinary subject that\n","may be loosely classified as a branch of artificial intelligence\n","and machine learning, both of which may include using\n","specific techniques and using general-purpose learning\n","methods. As an interdisciplinary field of research, it may seem\n","disorganized, with methods taken and reused from various\n","engineering and computer science disciplines. While one\n","specific vision issue may be readily solved with a hand-crafted\n","statistical technique, another may need a vast and\n","sophisticated ensemble of generic machine learning\n","algorithms. Computer vision as a discipline is at the cutting\n","edge of science. As with any frontier, it is thrilling and chaotic,\n","with often no trustworthy authority to turn to. Numerous\n","beneficial concepts lack a theoretical foundation, and some\n","theories are rendered ineffective in reality; developed regions\n","are widely dispersed, and often one seems totally unreachable\n","from the other.\n","\"\"\""],"metadata":{"id":"Iz9huFjXUfIf","executionInfo":{"status":"ok","timestamp":1708277913607,"user_tz":-330,"elapsed":689,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["! pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYgcxhLCVU4a","executionInfo":{"status":"ok","timestamp":1708277923579,"user_tz":-330,"elapsed":9977,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"ae15a000-7851-467e-ac36-43392ae9d47b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m184.3/226.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n","Installing collected packages: h11, httpcore, httpx, openai\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 openai-1.12.0\n"]}]},{"cell_type":"code","source":["chat_messages=[\n","    SystemMessage(content='You are an expert assistant with expertize in summarizing Research papers '),\n","    HumanMessage(content=f'Please provide a short and concise summary of the following abstract from a research paper:\\n TEXT: {abstract}')\n","]\n","\n","llm=ChatOpenAI(model_name='gpt-3.5-turbo')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D461vqsCUfFa","executionInfo":{"status":"ok","timestamp":1708277925216,"user_tz":-330,"elapsed":1651,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"8ea13526-a29d-4297-dec5-be793f864bdf"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n","  warn_deprecated(\n"]}]},{"cell_type":"code","source":["! pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJhHCJ5yVkg_","executionInfo":{"status":"ok","timestamp":1708277935823,"user_tz":-330,"elapsed":10615,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"1e9072e7-743c-495a-e613-4d02a5c0a116"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tiktoken\n","  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n","Installing collected packages: tiktoken\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tiktoken-0.6.0\n"]}]},{"cell_type":"code","source":["## total tokens\n","llm.get_num_tokens(abstract)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"twzaHWQtVRK4","executionInfo":{"status":"ok","timestamp":1708277937876,"user_tz":-330,"elapsed":2070,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"dc12bef0-cb42-4ecf-e11b-5cb216233a8b"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["221"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["llm(chat_messages).content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246},"id":"b03eGdJGVgI0","executionInfo":{"status":"ok","timestamp":1708277940620,"user_tz":-330,"elapsed":2751,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"2f6fdc4c-6e64-4d46-90de-58862184c92e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n"]},{"output_type":"execute_result","data":{"text/plain":["'Computer vision is a multidisciplinary area of research focused on enabling computers to interpret visual data. It is considered a branch of artificial intelligence and machine learning, with a mix of specific techniques and general-purpose learning methods utilized. The field is characterized by a variety of approaches taken from different disciplines, with some vision problems requiring tailored statistical techniques while others necessitate complex machine learning algorithms. Computer vision is an evolving field with no definitive authority, where innovative concepts may lack theoretical backing and certain theories may not be effective in practice. The discipline is dynamic, with challenges and advancements dispersed across a wide range of topics.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["##get_summary\n","print(llm(chat_messages).content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jmi08pjnVqbF","executionInfo":{"status":"ok","timestamp":1708277942630,"user_tz":-330,"elapsed":2018,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"bc1a171f-1640-40a8-d436-b2600be5c8c0"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Computer vision is a research field focused on enabling computers to interpret visual data to understand the world at an abstract level. It is considered a branch of artificial intelligence and machine learning, incorporating various techniques from different disciplines. While some vision problems can be solved with specific statistical methods, others require complex machine learning algorithms. Computer vision is a dynamic and interdisciplinary field with no clear authority, leading to a mix of practical and theoretical challenges.\n"]}]},{"cell_type":"markdown","source":["# Prompt Template Text Summarization --- LANGUAGE"],"metadata":{"id":"Bt2UPgdWaBZV"}},{"cell_type":"code","source":["from langchain.chains import LLMChain\n","from langchain import PromptTemplate"],"metadata":{"id":"prx6eARuWv7O","executionInfo":{"status":"ok","timestamp":1708277943578,"user_tz":-330,"elapsed":954,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["generic_template='''\n","Write a summary of the following Abstract :\n","Abstract Summary : `{abstract}`\n","Translate the precise summary to {language}.\n","\n","'''\n","prompt=PromptTemplate(\n","    input_variables=['abstract','language'],\n","    template=generic_template\n",")"],"metadata":{"id":"8JEgbUYJaOHU","executionInfo":{"status":"ok","timestamp":1708277943579,"user_tz":-330,"elapsed":11,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["prompt.format(abstract=abstract,language='Hindi')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"D24SJvlJbDrr","executionInfo":{"status":"ok","timestamp":1708277943579,"user_tz":-330,"elapsed":10,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"ffc26efb-3b22-4876-9c2a-26e625de1827"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nWrite a summary of the following Abstract :\\nAbstract Summary : `\\nComputer vision is an area of research concerned \\nwith assisting computers in seeing. Computer vision issues aim \\nto infer something about the world from observed picture data \\nat the most abstract level. It is a multidisciplinary subject that \\nmay be loosely classified as a branch of artificial intelligence\\nand machine learning, both of which may include using \\nspecific techniques and using general-purpose learning \\nmethods. As an interdisciplinary field of research, it may seem \\ndisorganized, with methods taken and reused from various \\nengineering and computer science disciplines. While one \\nspecific vision issue may be readily solved with a hand-crafted \\nstatistical technique, another may need a vast and \\nsophisticated ensemble of generic machine learning \\nalgorithms. Computer vision as a discipline is at the cutting \\nedge of science. As with any frontier, it is thrilling and chaotic, \\nwith often no trustworthy authority to turn to. Numerous \\nbeneficial concepts lack a theoretical foundation, and some \\ntheories are rendered ineffective in reality; developed regions \\nare widely dispersed, and often one seems totally unreachable \\nfrom the other.\\n`\\nTranslate the precise summary to Hindi.\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["complete_prompt=prompt.format(abstract=abstract,language='Hindi')"],"metadata":{"id":"idCxXEUtbJWm","executionInfo":{"status":"ok","timestamp":1708277943580,"user_tz":-330,"elapsed":9,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["llm.get_num_tokens(complete_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"djv6hZvDcQy_","executionInfo":{"status":"ok","timestamp":1708277944304,"user_tz":-330,"elapsed":733,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"e5839e31-70e4-4ab5-d010-321c3ee7b58c"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["241"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["llm_chain=LLMChain(llm=llm,prompt=prompt)\n","summary=llm_chain.run({'abstract':abstract,'language':'hindi'})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RdNSRM7cYOk","executionInfo":{"status":"ok","timestamp":1708277955906,"user_tz":-330,"elapsed":11608,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"9a9ccd64-64c1-4d39-bb85-f46fae68a22c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n"]}]},{"cell_type":"code","source":["summary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"id":"1UfjE6pdce9T","executionInfo":{"status":"ok","timestamp":1708277955907,"user_tz":-330,"elapsed":30,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"19e42652-0770-4c81-f2e9-4fd341b856cc"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'कम्प्यूटर दृश्य एक शोध क्षेत्र है जो कंप्यूटरों को देखने में सहायता करने के संबंध में चिंतित है। कंप्यूटर दृश्य मुद्दों का लक्ष्य सबसे अध्यात्मिक स्तर पर देखी गई चित्र आंकड़ा से कुछ जानने का है। यह एक बहुविज्ञानिक विषय है जो आमतौर पर कृत्रिम बुद्धिमत्ता और मशीन शिक्षा की शाखा के रूप में वर्गीकृत किया जा सकता है, जिसमें विशेष तकनीकों का उपयोग करना और सामान्य उपयोग करने के विधियों का उपयोग किया जा सकता है। एक अन्तर्विज्ञानी क्षेत्र के रूप में, यह असंगठित लग सकता है, जिसमें विभिन्न इंजीनियरिंग और कंप्यूटर विज्ञान शाखाओं से लिए और पुन: प्रयोग किए गए विधियों का उपयोग किया जाता है। कम्प्यूटर दृश्य के रूप में एक शिक्षा तांत्रिक शिक्षा है। किसी विशेष दृश्य समस्या को एक हाथ-रचित सांख्यिक तकनीक से आसानी से हल किया जा सकता है, दूसरा एक भारी और परिष्कृत संगठन की आवश्यकता हो सकती है।'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# Marathi"],"metadata":{"id":"Y9hveX8Pzq3P"}},{"cell_type":"code","source":["prompt.format(abstract=abstract,language='Marathi')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"67QrfqLzzVZi","executionInfo":{"status":"ok","timestamp":1708277955907,"user_tz":-330,"elapsed":27,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"6ea05f17-0980-463d-9738-475a254acc23"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nWrite a summary of the following Abstract :\\nAbstract Summary : `\\nComputer vision is an area of research concerned \\nwith assisting computers in seeing. Computer vision issues aim \\nto infer something about the world from observed picture data \\nat the most abstract level. It is a multidisciplinary subject that \\nmay be loosely classified as a branch of artificial intelligence\\nand machine learning, both of which may include using \\nspecific techniques and using general-purpose learning \\nmethods. As an interdisciplinary field of research, it may seem \\ndisorganized, with methods taken and reused from various \\nengineering and computer science disciplines. While one \\nspecific vision issue may be readily solved with a hand-crafted \\nstatistical technique, another may need a vast and \\nsophisticated ensemble of generic machine learning \\nalgorithms. Computer vision as a discipline is at the cutting \\nedge of science. As with any frontier, it is thrilling and chaotic, \\nwith often no trustworthy authority to turn to. Numerous \\nbeneficial concepts lack a theoretical foundation, and some \\ntheories are rendered ineffective in reality; developed regions \\nare widely dispersed, and often one seems totally unreachable \\nfrom the other.\\n`\\nTranslate the precise summary to Marathi.\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["complete_prompt=prompt.format(abstract=abstract,language='Marathi')"],"metadata":{"id":"G3viRxmUzVWK","executionInfo":{"status":"ok","timestamp":1708277955907,"user_tz":-330,"elapsed":25,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["llm.get_num_tokens(complete_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0SMhsYzzVTf","executionInfo":{"status":"ok","timestamp":1708277955908,"user_tz":-330,"elapsed":26,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"3ae66327-953f-4b85-cf18-0fdcb86364cb"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["242"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["llm_chain=LLMChain(llm=llm,prompt=prompt)\n","summary=llm_chain.run({'abstract':abstract,'language':'marathi'})"],"metadata":{"id":"LgwZyTe9zVRK","executionInfo":{"status":"ok","timestamp":1708277992309,"user_tz":-330,"elapsed":36424,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["summary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"ejqJQrDvzVO1","executionInfo":{"status":"ok","timestamp":1708277992310,"user_tz":-330,"elapsed":24,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"7f0f0bd8-a0f3-4b7e-9333-9523bba5a1d8"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'संगणक दृष्टिकोन हे एक अनुसंधान क्षेत्र आहे ज्यात संगणकांना दृश्य प्राप्त करण्यास मदत करण्याची चिंता आहे. संगणक दृष्टिकोन समस्यांना प्राथमिक स्तरावर दृश्यातून काहीतरी काही ओळखून काढण्याचा उद्दीष्ट आहे. हे एक बहुविद्यावर्ती विषय आहे ज्याला कृत्रिम बुद्धिमत्ता आणि मशीन शिक्षणच्या शाखा म्हणून सांगितले जाऊ शकते, ज्यात काही विशेष तंत्रज्ञानिक तंत्रे वापरली जातील आणि सामान्य विद्यार्थी शिक्षण पद्धती वापरली जातील. एक अन्य अन्वेषण समस्या हातकलित सांगटली जाऊ शकते, पण दुसरी व्यापक आणि सुदृढ मशीन शिक्षण अल्गोरिदमची संभाव्य परिस्थिती आवश्यक आहे. संगणक दृष्टिकोन हा विज्ञानाचा कोनातरी सर्वाधिक भागात आहे. यात काहीच निर्देशक संस्था असल्याचे असून ते अविश्वसनीय किंवा अविश्वसनीय दिसू शकतात. कितीही उपयुक्त अवधान वैज्ञानिक आधार नाहीत आणि काही सिद्धांत वास्तवात अकारणी झाले आहेत; विकसित क्षेत्र विविध आहेत, आणि काहीच वास्तवात एकमेकांपासून पूर्णतः अदृश्य दिसू शकतात.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["## StuffDocumentChain Text Summarization"],"metadata":{"id":"YT8JV6IZsSye"}},{"cell_type":"code","source":["! pip install PyPDF2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cm5XOU8zsbT6","executionInfo":{"status":"ok","timestamp":1708277999572,"user_tz":-330,"elapsed":7283,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"1c2d8e36-d9c7-40de-b3f2-7c771db3b194"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m174.1/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2\n","Successfully installed PyPDF2-3.0.1\n"]}]},{"cell_type":"code","source":["from PyPDF2 import PdfReader"],"metadata":{"id":"G8L7eEdAcj3h","executionInfo":{"status":"ok","timestamp":1708277999572,"user_tz":-330,"elapsed":33,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# provide the path of  pdf file/files.\n","pdfreader = PdfReader('opencv.pdf')"],"metadata":{"id":"9aS1YzoksZd3","executionInfo":{"status":"ok","timestamp":1708278949085,"user_tz":-330,"elapsed":2,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["from typing_extensions import Concatenate\n","# read text from pdf\n","text = ''\n","for i, page in enumerate(pdfreader.pages):\n","    content = page.extract_text()\n","    if content:\n","        text += content"],"metadata":{"id":"yGTvJGgfs12d","executionInfo":{"status":"ok","timestamp":1708278950724,"user_tz":-330,"elapsed":1083,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"1zO2j0CGtayX","executionInfo":{"status":"ok","timestamp":1708278950724,"user_tz":-330,"elapsed":16,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"fb2d2688-56bd-4e7d-905f-06d56c6d51a2"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/353326963\\nARTIFICIAL INTELLIGENCE IN COMPUTER VISION\\nArticle  · July 2021\\nDOI: 10.33564/IJEAS T.2021. v06i01.037\\nCITATIONS\\n4READS\\n10,186\\n1 author:\\nAryan Karn\\nMotilal Nehru National Instit ute of T echnolog y\\n3 PUBLICA TIONS \\xa0\\xa0\\xa04 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Aryan Karn  on 18 July 2021.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.                      International Journal of Engineering Applied Sciences and Technology , 2021    \\n    Vol. 6, Issue 1, ISSN No. 2455 -2143, Pages 249-254 \\n                                  Published Online May 2021 in IJEAST (http://www.ijeast.com)                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n \\n249 \\n \\nARTIFICIAL INTELLIGENCE IN \\nCOMPUTER VISION  \\nAryan Karn  \\nMotilal Nehru National Institute of Technology Allahabad, Prayagraj  \\nDepartment of Electronics and Communication Engineering  \\n \\nAbstract - Computer vision is an area of research concerned \\nwith assisting computers in seeing. Computer vision issues aim \\nto infer something about the world from observed picture data \\nat the most abstract level. It is a multidisciplinary subject that \\nmay be loosely classified as a branch of artificial intelligence  \\nand machine learning, both of which may include using \\nspecific techniques and using general -purpose learning \\nmethods.  As an interdisciplinary field of research, it may seem \\ndisorganized, with methods taken and reused from various \\nengineering and computer science disciplines. While one \\nspecific vision issue may be readily solved with a hand -crafted \\nstatistical technique, another may need a vast and \\nsophisticated ensemble of generic machine learning \\nalgorithms . Computer vision as a discipline is at the cutting \\nedge of science. As with any frontier, it is thrilling and chaotic, \\nwith often no trustworthy authority to turn to. Numerous \\nbeneficial concepts lack a theoretical foundation, and some \\ntheories are render ed ineffective in reality; developed regions \\nare widely dispersed, and often one seems totally unreachable \\nfrom the other.  \\nKeywords —Computer vision, Artificial intelligence, Neural networks, \\nCNN., Deep learning, machine learning  \\nI. INTRODUCTION  \\n     Recently, computer vision has gained traction and popularity \\nas a consequence of the many applications it has found in areas \\nlike health and medical, sports and entertainment, automaton \\ndesign, and self -driving cars. Many of these applications rely on  \\nvisual recognition tasks such as image order, restriction, and \\nidentification. Recent advances in Convolutional Neural Networks \\n(CNNs) have resulted in an extraordinary performance in these \\nbest-in-class visual recognition assignments and frameworks, \\ndemo nstrating the power of Convolutional Neural Networks. \\nConsequently, convolutional neural networks (CNNs) have \\nemerged as the basic building blocks of deep learning \\ncomputations in computer vision.  \\nDeep Neural Networks (DNN) is a kind of neural network that  has \\nbetter image identification skills and is often utilized in computer \\nvision computations. Convolutional Neural Networks (CNN or \\nConvNet) is a subtype of Deep Neural Networks (DNNs) that are often employed in visual sign decoding. In addition, it is us ed in \\nComputer Vision and Natural Language Processing to organize \\nmaterial (NLP). It is possible to construct a convolutional neural \\nnetwork using a variety of structural blocks. These structural \\nblocks include convolution layers, pooling layers, and fully  \\nconnected layers, all of which will be discussed briefly in this \\narticle. In the next sections, the author covers Deep Learning and \\nthe many neural network techniques lumped together. In addition, \\nthe book covers Convolutional Neural Networks, their \\nconst ruction, and their applications in several fields, including \\nmedicine and engineering.  \\nII. LITERATURE SURVEY  \\nA. Deep Learning and Neural Networks  \\nMachine Learning is a subset of Deep Learning, a subset of \\nArtificial Intelligence (AI). Machine learning uses  algorithms and \\ntraining data to automatically detect patterns and with little human \\nintervention. Artificial Intelligence is a method for teaching \\ncomputers to act like humans. At the same time, Deep Learning is \\ninspired by the structure and function of t he human brain, as \\nrepresented symbolically by an artificial neural network. [12] \\nWhile deep learning was originally proposed in the 1980s, it has \\nshown significant benefits in recent years for two primary reasons:  \\nA. This requires a significant level of k nowledge. For instance, the \\ndevelopment of autonomous vehicles necessitates the collection of \\nmany pictures and lengthy video recordings.  \\nB. Deep learning requires a large capacity for recording. High -\\nperformance GPUs offer an efficient parallel design tha t is well -\\nsuited for deep learning. When used in conjunction with clusters \\nor cloud computing, this significantly lowers the time required to \\ntrain a deep learning network from weeks to hours or less. [11]. \\nDeep learning may be used to solve a wide range o f problems. For \\nexample, the author discusses autonomous driving, aerospace and \\nmilitary, medical research, industrial automation, and electronics \\nin more detail in the closing part of the article.  \\nIn general, a Neural Network is a kind of algorithm that a ccepts \\ncertain input parameters and processes them using an Activation \\nFunction to get the desired Output. In this method, the input to                       International Journal of Engineering Applied Sciences and Technology , 2021    \\n    Vol. 6, Issue 1, ISSN No. 2455 -2143, Pages 249-254 \\n                                  Published Online May 2021 in IJEAST (http://www.ijeast.com)                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n \\n250 \\n \\noutput processing component is referred to as a neuron. Consider \\nthe fundamental example of calculating the purchase pri ce of a \\nhome. Numerous factors must be taken into account, each of \\nwhich has an impact on the Price component. For instance, the \\nsquare footage of the room, the number of bedrooms, and the zip \\ncode. Thus, if we take price as an Output, the following Neural  \\nNetwork shows how a neural network could produce that Output \\nusing the parameters stated earlier as inputs.  \\n \\nFig 1: An example of Standard Neural Network [1]  \\nEach circle represents a neuron that is given an Activation \\nFunction that computes the desired Output by combining distinct \\nvalues for various input parameters. The Activation Function is \\ndetermined by the algorithm\\'s purpose/application. For instance, \\neach circle represents a neuron that is given an Activation \\nFunction that computes the desired Output by combining distinct \\nvalues for various input parameters. The Activation Function is \\ndetermined by the algorithm\\'s purpose/application. For instance, \\nin the  above example, the objective is to determine the maximum \\nprice of a house. For the sake of simplicity, let us suppose that the \\nOutput is solely dependent on two input variables, namely the size \\nand number of bedrooms. In this instance, the bigger the hous e and \\nthe more bedrooms, the greater the price of the house. Thus, the \\nActivation Function (Neuron) will be defined in such a manner \\nthat it will pick the greatest possible value for each input parameter \\nand then compute the Output. Obviously, this seems t o be very \\neasy in this case, but when a large number of factors are involved, \\ndecision -making is not as straightforward as it appears based on \\nmaximum or minimum values alone. And here is where Data -\\nDriven Machine Learning comes into play. The method takes  \\nadvantage of data saved (learned!) from previous instances in \\norder to calculate the optimal Output using the Activation \\nFunction. The above example shows a Standard Neural Network, \\nwhich is often used to generate Output from statistical, numerical, \\nand o ther quantitative data. The kind of Neural Network to employ \\nis determined by the nature of the input data that the algorithm \\nmust handle. The following table summarizes the capabilities of \\ndifferent Neural Networks in processing various kinds of input \\ndata. [1] In the remainder of this article, the author will concentrate \\nonly on the Convolutional Neural Network method used in Deep \\nLearning.  \\nB. Deep Learning using Convolutional Neural Network for \\nComputer Vision       In deep learning, a convolutional neura l network (CNN), often \\nknown as a ConvNet, is a kind of deep neural network that is \\nfrequently used to analyze visual pictures. In certain areas, it is \\nalso referred to as a convolutional neural network (CNN). These \\nartificial neural networks are referred to as shift -invariant artificial \\nneural networks or space -invariant artificial neural networks due \\nto their shared -weights architecture and translation invariance \\nproperties (SIANNs). Algorithms may be used to identify pictures \\nand videos, create recommend er systems, categorize images, do \\nmedical image analysis, and evaluate natural language. In the next \\npart, the author discusses what Convolution is, how it extracts data \\nfrom pictures, and the architecture and components of CNN, \\namong other things. This wi ll show how CNN examines the \\ncontent of an image and processes the data in order to provide the \\nintended result to the audience.  \\nC. Architectural Overview  \\nConvolution is a mathematical procedure that takes two functions \\nand produces a third function that illustrates how the shape of one \\nfunction is affected by the shape of the other. To complete the \\noperation, the Convolution process requires the calculation of the \\nResult function, as well as the initialization of the Result function. \\nConvolution is a data  processing technique that entails \\ncategorizing the components (content) of an image in order to \\nassist Machine Learning and ultimately generate the desired \\nOutput through the algorithm. It is utilized in the processing of \\npicture data. Deep Learning and N eural Networks are two \\ndifferent types of neural networks that are capable of analyzing \\nimage data. Deep Learning is a kind of neural network that enables \\ndata-driven learning. As indicated by the procedure\\'s name, the \\nconvolution process separates the whe at from the chaff.  \\nThis structure may be seen as a three -dimensional volume of \\nneurons in a cellular environment. A distinguishing feature of how \\nCNNs have evolved from earlier feed -forward versions is their \\nability to improve computational efficiency via the addition of \\nnew layer types to their design. How about we take a closer look \\nat the general design of CNNs right now? [4]  \\nD. Basic CNN components  \\n1. Convolutional Layer:  \\n     CNN, or convolutional neural network, is a kind of neural \\nnetwork model that is designed for dealing with two -dimensional \\nimage data, although it may also be used to deal with one -\\ndimensional and three -dimensional data. Convolution is \\naccomplished via the use of a channel (a small matrix whose size \\nmay be chosen). In this channel, which travels the whole picture \\nnetwork, the task is to reproduce the image\\'s features by utilizing \\nthe pixel values that were first used. Each of these increases is \\nadded together to form a single number towards the end of the \\nprocess. When doing a compar ison action, the channel moves \\n                      International Journal of Engineering Applied Sciences and Technology , 2021    \\n    Vol. 6, Issue 1, ISSN No. 2455 -2143, Pages 249-254 \\n                                  Published Online May 2021 in IJEAST (http://www.ijeast.com)                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n \\n251 \\n \\nrightward by n units (this number may vary). After traversing over \\neach place, a framework is produced that is much less in size than \\nthe information grid that was previously constructed. [7]  \\n \\n \\nFig 3: Architecture of a CNN  [6] \\nEdge Detection Example:  \\n     In Figures 4 and 5 below, to detect the horizontal and vertical \\nimages with the help of a matrix, let\\'s consider a greyscale image, \\nwith a 6 x 6 matrix and a filter of 3x3 applied to it.[14]  \\n \\nFig 4: Identifying the edges [14] \\n \\nFig 5: Scanning of the image pattern [14]  \\nAfter the above calculations of the matrix, we get the matrix as \\nshown in fig:6. To calculate it, we take the initial 3 X 3 framework \\nfrom the 6 X 6 picture and increase it with the channel. Let’s  \\nconsider t he following matrix of 4x4 order and the calculation \\ntakes place as: for example,  3*1 + 0 + 1* -1 + 1*1 + 5*0 + 8* -1 + \\n2*1 + 7*0 + 2* -1 = - 5. To compute the second component of the \\n4 X 4 order, we will move the channel one step ahead to the right \\nside of t he original Greyscale matrix and so on: [14]  \\nFig 6:  Matrix calculation in convolutional layer [ 14]       \\n \\n \\n  \\nFig 7: Convolving over the entire image [ 14] \\nThe way to detect the vertical edge in the image is to look for the \\npixel values as, if the pixel values are greater, then brightness at \\nthat part of the image will be more, and if the value is less, it will \\nbe dark. [ 14] \\n2. Pooling Layer:  \\n     Spatial poo ling (alternatively referred to as subsampling or \\ndown sampling ) lowers the dimensionality of each element map \\nwhile preserving the most critical data. Spatial pooling may occur \\nin a number of ways: Quantifiers include the terms maximum, \\naverage, and total . If Max Pooling occurs, we define a spatial \\nneighborhood  (for example, a 22 -window neighborhood ) and \\nchoose the biggest component from the redressed highlight map \\ncontained inside that neighborhood . Rather than choosing the \\nbiggest component, we might cho ose the average (Average \\nPooling) or a total of all components included inside that window. \\nMax Pooling has been shown to be increasingly effective with \\ntime. [8] Max pooling, as shown below, chooses the component \\nwith the largest size from the rectified f eature map. Choosing the \\nbiggest component is equal to using the conventional pooling \\nmethod. The phrase \"sum pooling\" refers to the gathering of all \\ncomponents in an element map. [8]  \\n                      International Journal of Engineering Applied Sciences and Technology , 2021    \\n    Vol. 6, Issue 1, ISSN No. 2455 -2143, Pages 249-254 \\n                                  Published Online May 2021 in IJEAST (http://www.ijeast.com)                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n \\n252 \\n \\n     \\nFig 8: Max Pooling [8]  \\n3. Fully Connected Layers:  \\n     Fully Linked layers have every neuron in the layer above it \\nconnected to every neuron  in the layer below it. To put it simply, \\nFC works in the same manner as a conventional neural network, \\nsuch as a Multi -Layer Perceptron, does (MLP). The main \\ndistinction is that information sources would be molded  and \\norganized in the manner defined by earlier phases of a CNN, rather \\nthan the other way around. [7]. As illustrated in the diagram below, \\nthe feature map matrix is converted into a vector as(x1,x2,...xn) by \\nutilizing the FC layer, and the resulting vectors are merged to \\ncreate a model. Then, using the activation function, we can \\nclassify the Output into different categories.  \\n \\n \\n                                                 \\nFig 9: Fully connected Layer [ 7] \\nIII APPLICATIONS  \\nA. HealthCare:  \\n   Computer vision is extensively employed in the diagnosis of \\ndiseases by analyzing X -rays, magnetic resonance imaging (MRI), \\nand other medical pictures. It has been shown to be just as \\nconvincing as traditional human speciali sts in the area when it \\ncomes to accuracy. On a regular basis, Computer Vision is \\neffectively diagnosing pneumonia, cerebrum tumor’s , diabetes, Parkinson\\'s illness, malignant uterine growth, and a host of other \\nmedical issues, and the technology is getting  more advanced. With \\nthe use of best -in-class image processing technology and \\ncomputer vision methods, early identification of any potential \\ndiseases will be feasible. In this manner, treatment may be \\nadministered at an inconvenient time during the disease  or, in any \\nevent, the likelihood of their recurring is decreased [2].  \\n \\nFig 10: Cross -section of the 3D image of CT Scan and MRI [2]  \\n \\nB. Automobile:  \\n     With the expanded publicity of oneself driving autos, car \\nbusinesses are vigorously subject to Computer Vision since it is \\nintended for understanding the driving condition, including \\nidentifying impediments, people on footpaths, and conceivable \\ncrash ways. Self -driving autos are gradually advancing into the \\nmarket, with more organizations searching for imaginative \\napproaches to bring progressively electric vehicles onto the street. \\nComputer Vision innovation enables these self -driving vehicles \\'to \\nsee\\' the earth while AI calculations make the \"minds\" that help that \\nComputer Vision translate the items around the vehicle. Self -\\ndriving autos are furnished with numerous cameras to give a total \\n360-degree perspective on nature inside the scope of several \\nmeters. Tesla vehicles, for example, utilize something like 8 \\nencompasses cameras to accomplish this accomplishment. Twelve \\nultrasonic sensors for identifying hard and delicate articles out and \\nabout and a front -oriented radar that empowers the identification  \\nof different vehicles even through downpour or mist are \\nadditionally introduced to supplement the cameras. With a lot of \\ninformation being encouraged into the vehicle, a basic PC won\\'t \\nbe sufficient to deal with the inundation of data. This is the reason \\nall self -driving autos have a locally available PC with Computer \\nVision highlights made through AI. The cameras and sensors are \\nentrusted to both recognize and group protests in nature - like \\npeople on foot. The area, thickness, shape, and profundity of th e \\nitems must be considered quickly to empower the remainder of the \\ndriving framework to settle on proper choices. Every one of these \\ncalculations is just conceivable through the incorporation of AI \\nand deep neural systems, which results in highlights like the \\nperson on foot recognition [15].     \\n                      International Journal of Engineering Applied Sciences and Technology , 2021    \\n    Vol. 6, Issue 1, ISSN No. 2455 -2143, Pages 249-254 \\n                                  Published Online May 2021 in IJEAST (http://www.ijeast.com)                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n \\n253 \\n \\n \\n                                                    \\nFig 11: Tesla Car’s Vision, Source: Tesla [ 15] \\nC. Astronomy:  \\n     Our full understanding of the universe is based on photon \\nestimations, which are mostly compose d of pictures of the \\nuniverse. This opens the door to the potential of utilizing \\nComputer Vision in astronomy since our universe is so enormous, \\nand our universe\\'s lone natural rule predicts that the data gathered \\nwill be just as large. It will be impossib le for the stargazer, or for \\nanybody else, to physically contemplate this information in its \\nentirety. We can decipher all of the data in a short period of time, \\nthanks to Computer Vision. To put it another way, computer vision \\nis currently being utilized to find new planets and big bodies, with \\napplications such as exoplanet imaging, star and cosmic system \\ngrouping, and other similar tasks [3].  \\nD. Industrial:  \\n     In Industries, Computer Vision is utilized on the mechanical \\nproduction systems for checking groups, identifying harmed parts, \\nfor the examination of the completed merchandise. Here, Machine \\nVision apparatuses help in discovering infinitesimal level \\nsurrenders in items that basically can\\'t be distinguished through \\nhuman vision. In assembling under takings, perusing scanner tags \\nor QR code are fundamental as they give a one of a kind \\nrecognizable proof to an item. Perusing a great many standardized \\nidentifications in a day isn\\'t a simple errand for people; at the same \\ntime, it very well may be done e ffectively in minutes through \\nComputer Vision [ 3]. \\nIV ConvNet ARCHITECTURE  \\nConvolutional Neural Networks (CNNs) is a kind of neural \\nnetwork that has been around since the mid -90s. You\\'ll discover \\nsome more visually arresting designs in the section below [ 9]. \\nA convolutional neural network was in the process of being \\ncreated from the late 1990s to the middle of the 2010s, and it was \\nknown as LeNet during that time period. The tasks that \\nconvolutional neural networks were capable of doing grew increasingly f ascinating as an ever -increasing quantity of \\ninformation and processing power became accessible.  \\n(2).AlexNet (2012) – In 2012, Alex Krizhevsky (together with \\nothers) published AlexNet, which was a more in -depth and much \\nmore complete version of the LeNet. AlexNet was the clear winner \\nof the inaugural ImageNet Large Scale Visual Recognition \\nChallenge (ILSVRC) in 2012, outperforming the competition by \\na wide margin. This research represented a major advancement \\nover prior techniques, and the widespread use of  CNNs today may \\nbe linked back to the findings of this study.  \\nA Convolutional Network created by Matthew Zeiler and Rob \\nFergus was presented at the ILSVRC 2013 as part of the 3.ZF  Net \\n(2013) session. The ZDNet was the moniker that was given to this \\nnetwork (short for Zeiler and Fergus Net). It was feasible to make \\nimprovements to AlexNet by altering the design hyperparameters \\nused in its creation. When Szegedy and colleagues from G oogle \\npresented a Convolutional Network at the ILSVRC 2014 \\nconference, it was given the moniker \"GoogleLeNet\" (2014). This \\norganization\\'s main goal was the creation of an Inception Module \\nthat significantly decreased the number of parameters in the \\nsystem (4M, contrasted with AlexNet with 60M).  \\nIn the 2014 International Laser Scanning and Vision Research \\nConference (ILSVRC), a system that became known as the \\nVGGNet  was the first to cross the finish line. In particular, it aimed \\nat demonstrating how important it is for efficient execution to have \\na system with sufficient depth (i.e., layers). It was ResNets (2015), \\na Residual Network created by Kaiming He (and others ), that was \\nawarded sixth place in the ILSVRC 2015. ResNets (2015) was the \\nwinner of the ILSVRC 2015. Convolutional Neural Network \\nmodels such as ResNets are currently by a wide margin the best -\\nin-class models, and they will continue to be the default opti on for \\nutilizing ConvNets for the foreseeable future (as of May 2016).  \\nThe seventh source is DenseNet, which was launched in August \\n2016. A network of nodes that are closely packed together. This \\ndensely linked convolutional network, developed by Gao Huang  \\n(and others) and published recently, has each layer directly \\nconnected to every other layer in a feed -forward architecture, with \\neach layer being straightforwardly correlated with each other \\nlayer. Following the completion of five highly concentrated arti cle \\nacknowledgment benchmark assignments, the DenseNet was \\nfound to have gained substantial gains over prior best -in-class \\narchitectures, results revealed. View this video to see exactly how \\nthe Torch was carried out.  \\nV. CONCLUSION  \\n     At the beginning of  the paper, we discussed the overview of \\ndeep learning and how Neural networks in dep learning are \\ndeployed to process various inputs to gain desired outputs.  In the \\nlater part, the author has focused on Convolutional Neural \\n                      International Journal of Engineering Applied Sciences and Technology , 2021    \\n    Vol. 6, Issue 1, ISSN No. 2455 -2143, Pages 249-254 \\n                                  Published Online May 2021 in IJEAST (http://www.ijeast.com)                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n \\n254 \\n \\nNetwork and explained in detai l a convolution operation, the \\nsystem architecture of CNN, and how the layers of CNN work in \\ncoordination to identify the highlights and the patterns of an \\nimage. Using these algorithms author has described how CNN can \\nbe applied in various industries. Thr ough this paper, it can be \\nconcluded that CNN has become a very powerful tool in machine \\nlearning. By providing various images as input data at the machine \\nlearning phase can facilitate the learning process faster, and the \\ndata can be deployed for multiple -output functions, which is a \\nmajor advantage of CNN. Apart from the application, the author \\nmentioned in the earlier section that CNN is now also being \\nconsidered for IoT, Commercial, and domestic security systems. \\nThus, CNN has gained a very prominent pl ace in Data Engineering \\nand still is gaining.  \\nVI REFERENCES  \\n[1] Pulkit Sharma, Analytics Vidhya, An Introductory Guide to \\nDeep Learning and Neural Networks, 22 Oct. 2018, \\nhttps://www.analyticsvidhya.com/blog/2018/10/introduction -\\nneural -networks -deep-learni ng/ \\n[2] Khan, S. A Guide to Convolutional Neural Networks for \\nComputer Vision. Morgan &amp; Claypool, 2018.  \\n[3] Verma, Shiva. “Understanding 1D and 3D Convolution Neural \\nNetwork: Keras.” Medium, Towards Data Science, 1 Oct. 2019,  \\ntowardsdatascience.com/u nderstanding -1d-and-3d-convolution -\\nneural -network -keras -9d8f76e29610.  \\n[4] Upadhyay, Yash. “Computer Vision: A Study on Different \\nCNN Architectures and Their Applications.” Medium, AlumnAI \\nAcademy, 29 Mar. 2019, \\nmedium.com/alumnaiacademy/introduction -to-computer -vision -\\n4fc2a2ba9dc  \\n[5]CS231n Convolutional Neural Networks for Visual \\nRecognition, cs231n.github.io/convolutional -networks/.  \\n[6] “Autopilot.” Tesla, Inc, www.tesla.com/autopilot.  \\n[7] Deshpande, Adit. “A Beginner\\'s Guide To Understanding \\nConvolutiona l Neural Networks.”  \\nA Beginner\\'s Guide To Understanding Convolutional Neural \\nNetworks – Adit Deshpande – Engineering at forwarding | UCLA \\nCS \\'19,  \\nadeshpande3.github.io/adeshpande3.github.io/A -Beginner\\'s -\\nGuide -To-Understanding -Convolutional -Neural -Network s/.  \\n[8] Upadhyay, Yash. “Computer Vision: A Study On Different \\nCNN Architectures and Their Applications.” Medium, AlumnAI \\nAcademy, 29 Mar. 2019, medium.com/alumnaiacademy/introduction -to-computer -vision -\\n4fc2a2ba9dc.  \\n[9] Ujjwalkarn. “An Intuitive Explanat ion of Convolutional \\nNeural Networks.” The Data Science Blog, 29 May 2017, \\nhttps://www.ujjwalkarn.me/2016/08/11/intuitive -explanation -\\nconvnets/.  \\n[10] Gibson, Adam, and Josh Patterson. “Deep Learning.” \\nO\\'Reilly | Safari, O\\'Reilly Media, Inc.,   \\nwww.oreilly .com/library/view/deep -\\nlearning/9781491924570/ch04.html  \\n[11] “What Is Deep Learning?: How It Works, Techniques &amp; \\nApplications.” How It Works, Techniques &amp; Applications - \\nMATLAB &amp; Simulink, \\nwww.mathworks.com/discovery/deep -learning.html.  \\n[12] Br ownlee, Jason. “What Is Deep Learning?” Machine \\nLearning Mastery, 31 Oct. 2019, \\nmachinelearningmastery.com/what -is-deep-learning/.  \\nView publication stats'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["from langchain.docstore.document import Document"],"metadata":{"id":"2PBxoNPOtc0x","executionInfo":{"status":"ok","timestamp":1708278950724,"user_tz":-330,"elapsed":14,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["docs = [Document(page_content=text)]\n","docs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7eJ7d1jteeL","executionInfo":{"status":"ok","timestamp":1708278950725,"user_tz":-330,"elapsed":14,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"dd6ad5e2-3240-4f38-8c98-34c91e49900f"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(page_content='See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/353326963\\nARTIFICIAL INTELLIGENCE IN COMPUTER VISION\\nArticle  · July 2021\\nDOI: 10.33564/IJEAS T.2021. v06i01.037\\nCITATIONS\\n4READS\\n10,186\\n1 author:\\nAryan Karn\\nMotilal Nehru National Instit ute of T echnolog y\\n3 PUBLICA TIONS \\xa0\\xa0\\xa04 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Aryan Karn  on 18 July 2021.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.                      International Journal of Engineering Applied Sciences and Technology , 2021    \\n    Vol. 6, Issue 1, ISSN No. 2455 -2143, Pages 249-254 \\n                                  Published Online May 2021 in IJEAST (http://www.ijeast.com)                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n \\n249 \\n \\nARTIFICIAL INTELLIGENCE IN \\nCOMPUTER VISION  \\nAryan Karn  \\nMotilal Nehru National Institute of Technology Allahabad, Prayagraj  \\nDepartment of Electronics and Communication Engineering  \\n \\nAbstract - Computer vision is an area of research concerned \\nwith assisting computers in seeing. Computer vision issues aim \\nto infer something about the world from observed picture data \\nat the most abstract level. It is a multidisciplinary subject that \\nmay be loosely classified as a branch of artificial intelligence  \\nand machine learning, both of which may include using \\nspecific techniques and using general -purpose learning \\nmethods.  As an interdisciplinary field of research, it may seem \\ndisorganized, with methods taken and reused from various \\nengineering and computer science disciplines. While one \\nspecific vision issue may be readily solved with a hand -crafted \\nstatistical technique, another may need a vast and \\nsophisticated ensemble of generic machine learning \\nalgorithms . Computer vision as a discipline is at the cutting \\nedge of science. As with any frontier, it is thrilling and chaotic, \\nwith often no trustworthy authority to turn to. Numerous \\nbeneficial concepts lack a theoretical foundation, and some \\ntheories are render ed ineffective in reality; developed regions \\nare widely dispersed, and often one seems totally unreachable \\nfrom the other.  \\nKeywords —Computer vision, Artificial intelligence, Neural networks, \\nCNN., Deep learning, machine learning  \\nI. INTRODUCTION  \\n     Recently, computer vision has gained traction and popularity \\nas a consequence of the many applications it has found in areas \\nlike health and medical, sports and entertainment, automaton \\ndesign, and self -driving cars. Many of these applications rely on  \\nvisual recognition tasks such as image order, restriction, and \\nidentification. Recent advances in Convolutional Neural Networks \\n(CNNs) have resulted in an extraordinary performance in these \\nbest-in-class visual recognition assignments and frameworks, \\ndemo nstrating the power of Convolutional Neural Networks. \\nConsequently, convolutional neural networks (CNNs) have \\nemerged as the basic building blocks of deep learning \\ncomputations in computer vision.  \\nDeep Neural Networks (DNN) is a kind of neural network that  has \\nbetter image identification skills and is often utilized in computer \\nvision computations. Convolutional Neural Networks (CNN or \\nConvNet) is a subtype of Deep Neural Networks (DNNs) that are often employed in visual sign decoding. In addition, it is us ed in \\nComputer Vision and Natural Language Processing to organize \\nmaterial (NLP). It is possible to construct a convolutional neural \\nnetwork using a variety of structural blocks. These structural \\nblocks include convolution layers, pooling layers, and fully  \\nconnected layers, all of which will be discussed briefly in this \\narticle. In the next sections, the author covers Deep Learning and \\nthe many neural network techniques lumped together. In addition, \\nthe book covers Convolutional Neural Networks, their \\nconst ruction, and their applications in several fields, including \\nmedicine and engineering.  \\nII. LITERATURE SURVEY  \\nA. Deep Learning and Neural Networks  \\nMachine Learning is a subset of Deep Learning, a subset of \\nArtificial Intelligence (AI). Machine learning uses  algorithms and \\ntraining data to automatically detect patterns and with little human \\nintervention. Artificial Intelligence is a method for teaching \\ncomputers to act like humans. At the same time, Deep Learning is \\ninspired by the structure and function of t he human brain, as \\nrepresented symbolically by an artificial neural network. [12] \\nWhile deep learning was originally proposed in the 1980s, it has \\nshown significant benefits in recent years for two primary reasons:  \\nA. This requires a significant level of k nowledge. For instance, the \\ndevelopment of autonomous vehicles necessitates the collection of \\nmany pictures and lengthy video recordings.  \\nB. Deep learning requires a large capacity for recording. High -\\nperformance GPUs offer an efficient parallel design tha t is well -\\nsuited for deep learning. When used in conjunction with clusters \\nor cloud computing, this significantly lowers the time required to \\ntrain a deep learning network from weeks to hours or less. [11]. \\nDeep learning may be used to solve a wide range o f problems. For \\nexample, the author discusses autonomous driving, aerospace and \\nmilitary, medical research, industrial automation, and electronics \\nin more detail in the closing part of the article.  \\nIn general, a Neural Network is a kind of algorithm that a ccepts \\ncertain input parameters and processes them using an Activation \\nFunction to get the desired Output. In this method, the input to                       International Journal of Engineering Applied Sciences and Technology , 2021    \\n    Vol. 6, Issue 1, ISSN No. 2455 -2143, Pages 249-254 \\n                                  Published Online May 2021 in IJEAST (http://www.ijeast.com)                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n \\n250 \\n \\noutput processing component is referred to as a neuron. Consider \\nthe fundamental example of calculating the purchase pri ce of a \\nhome. Numerous factors must be taken into account, each of \\nwhich has an impact on the Price component. For instance, the \\nsquare footage of the room, the number of bedrooms, and the zip \\ncode. Thus, if we take price as an Output, the following Neural  \\nNetwork shows how a neural network could produce that Output \\nusing the parameters stated earlier as inputs.  \\n \\nFig 1: An example of Standard Neural Network [1]  \\nEach circle represents a neuron that is given an Activation \\nFunction that computes the desired Output by combining distinct \\nvalues for various input parameters. The Activation Function is \\ndetermined by the algorithm\\'s purpose/application. For instance, \\neach circle represents a neuron that is given an Activation \\nFunction that computes the desired Output by combining distinct \\nvalues for various input parameters. The Activation Function is \\ndetermined by the algorithm\\'s purpose/application. For instance, \\nin the  above example, the objective is to determine the maximum \\nprice of a house. For the sake of simplicity, let us suppose that the \\nOutput is solely dependent on two input variables, namely the size \\nand number of bedrooms. In this instance, the bigger the hous e and \\nthe more bedrooms, the greater the price of the house. Thus, the \\nActivation Function (Neuron) will be defined in such a manner \\nthat it will pick the greatest possible value for each input parameter \\nand then compute the Output. Obviously, this seems t o be very \\neasy in this case, but when a large number of factors are involved, \\ndecision -making is not as straightforward as it appears based on \\nmaximum or minimum values alone. And here is where Data -\\nDriven Machine Learning comes into play. The method takes  \\nadvantage of data saved (learned!) from previous instances in \\norder to calculate the optimal Output using the Activation \\nFunction. The above example shows a Standard Neural Network, \\nwhich is often used to generate Output from statistical, numerical, \\nand o ther quantitative data. The kind of Neural Network to employ \\nis determined by the nature of the input data that the algorithm \\nmust handle. The following table summarizes the capabilities of \\ndifferent Neural Networks in processing various kinds of input \\ndata. [1] In the remainder of this article, the author will concentrate \\nonly on the Convolutional Neural Network method used in Deep \\nLearning.  \\nB. Deep Learning using Convolutional Neural Network for \\nComputer Vision       In deep learning, a convolutional neura l network (CNN), often \\nknown as a ConvNet, is a kind of deep neural network that is \\nfrequently used to analyze visual pictures. In certain areas, it is \\nalso referred to as a convolutional neural network (CNN). These \\nartificial neural networks are referred to as shift -invariant artificial \\nneural networks or space -invariant artificial neural networks due \\nto their shared -weights architecture and translation invariance \\nproperties (SIANNs). Algorithms may be used to identify pictures \\nand videos, create recommend er systems, categorize images, do \\nmedical image analysis, and evaluate natural language. In the next \\npart, the author discusses what Convolution is, how it extracts data \\nfrom pictures, and the architecture and components of CNN, \\namong other things. This wi ll show how CNN examines the \\ncontent of an image and processes the data in order to provide the \\nintended result to the audience.  \\nC. Architectural Overview  \\nConvolution is a mathematical procedure that takes two functions \\nand produces a third function that illustrates how the shape of one \\nfunction is affected by the shape of the other. To complete the \\noperation, the Convolution process requires the calculation of the \\nResult function, as well as the initialization of the Result function. \\nConvolution is a data  processing technique that entails \\ncategorizing the components (content) of an image in order to \\nassist Machine Learning and ultimately generate the desired \\nOutput through the algorithm. It is utilized in the processing of \\npicture data. Deep Learning and N eural Networks are two \\ndifferent types of neural networks that are capable of analyzing \\nimage data. Deep Learning is a kind of neural network that enables \\ndata-driven learning. As indicated by the procedure\\'s name, the \\nconvolution process separates the whe at from the chaff.  \\nThis structure may be seen as a three -dimensional volume of \\nneurons in a cellular environment. A distinguishing feature of how \\nCNNs have evolved from earlier feed -forward versions is their \\nability to improve computational efficiency via the addition of \\nnew layer types to their design. How about we take a closer look \\nat the general design of CNNs right now? [4]  \\nD. Basic CNN components  \\n1. Convolutional Layer:  \\n     CNN, or convolutional neural network, is a kind of neural \\nnetwork model that is designed for dealing with two -dimensional \\nimage data, although it may also be used to deal with one -\\ndimensional and three -dimensional data. Convolution is \\naccomplished via the use of a channel (a small matrix whose size \\nmay be chosen). In this channel, which travels the whole picture \\nnetwork, the task is to reproduce the image\\'s features by utilizing \\nthe pixel values that were first used. Each of these increases is \\nadded together to form a single number towards the end of the \\nprocess. When doing a compar ison action, the channel moves \\n                      International Journal of Engineering Applied Sciences and Technology , 2021    \\n    Vol. 6, Issue 1, ISSN No. 2455 -2143, Pages 249-254 \\n                                  Published Online May 2021 in IJEAST (http://www.ijeast.com)                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n \\n251 \\n \\nrightward by n units (this number may vary). After traversing over \\neach place, a framework is produced that is much less in size than \\nthe information grid that was previously constructed. [7]  \\n \\n \\nFig 3: Architecture of a CNN  [6] \\nEdge Detection Example:  \\n     In Figures 4 and 5 below, to detect the horizontal and vertical \\nimages with the help of a matrix, let\\'s consider a greyscale image, \\nwith a 6 x 6 matrix and a filter of 3x3 applied to it.[14]  \\n \\nFig 4: Identifying the edges [14] \\n \\nFig 5: Scanning of the image pattern [14]  \\nAfter the above calculations of the matrix, we get the matrix as \\nshown in fig:6. To calculate it, we take the initial 3 X 3 framework \\nfrom the 6 X 6 picture and increase it with the channel. Let’s  \\nconsider t he following matrix of 4x4 order and the calculation \\ntakes place as: for example,  3*1 + 0 + 1* -1 + 1*1 + 5*0 + 8* -1 + \\n2*1 + 7*0 + 2* -1 = - 5. To compute the second component of the \\n4 X 4 order, we will move the channel one step ahead to the right \\nside of t he original Greyscale matrix and so on: [14]  \\nFig 6:  Matrix calculation in convolutional layer [ 14]       \\n \\n \\n  \\nFig 7: Convolving over the entire image [ 14] \\nThe way to detect the vertical edge in the image is to look for the \\npixel values as, if the pixel values are greater, then brightness at \\nthat part of the image will be more, and if the value is less, it will \\nbe dark. [ 14] \\n2. Pooling Layer:  \\n     Spatial poo ling (alternatively referred to as subsampling or \\ndown sampling ) lowers the dimensionality of each element map \\nwhile preserving the most critical data. Spatial pooling may occur \\nin a number of ways: Quantifiers include the terms maximum, \\naverage, and total . If Max Pooling occurs, we define a spatial \\nneighborhood  (for example, a 22 -window neighborhood ) and \\nchoose the biggest component from the redressed highlight map \\ncontained inside that neighborhood . Rather than choosing the \\nbiggest component, we might cho ose the average (Average \\nPooling) or a total of all components included inside that window. \\nMax Pooling has been shown to be increasingly effective with \\ntime. [8] Max pooling, as shown below, chooses the component \\nwith the largest size from the rectified f eature map. Choosing the \\nbiggest component is equal to using the conventional pooling \\nmethod. The phrase \"sum pooling\" refers to the gathering of all \\ncomponents in an element map. [8]  \\n                      International Journal of Engineering Applied Sciences and Technology , 2021    \\n    Vol. 6, Issue 1, ISSN No. 2455 -2143, Pages 249-254 \\n                                  Published Online May 2021 in IJEAST (http://www.ijeast.com)                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n \\n252 \\n \\n     \\nFig 8: Max Pooling [8]  \\n3. Fully Connected Layers:  \\n     Fully Linked layers have every neuron in the layer above it \\nconnected to every neuron  in the layer below it. To put it simply, \\nFC works in the same manner as a conventional neural network, \\nsuch as a Multi -Layer Perceptron, does (MLP). The main \\ndistinction is that information sources would be molded  and \\norganized in the manner defined by earlier phases of a CNN, rather \\nthan the other way around. [7]. As illustrated in the diagram below, \\nthe feature map matrix is converted into a vector as(x1,x2,...xn) by \\nutilizing the FC layer, and the resulting vectors are merged to \\ncreate a model. Then, using the activation function, we can \\nclassify the Output into different categories.  \\n \\n \\n                                                 \\nFig 9: Fully connected Layer [ 7] \\nIII APPLICATIONS  \\nA. HealthCare:  \\n   Computer vision is extensively employed in the diagnosis of \\ndiseases by analyzing X -rays, magnetic resonance imaging (MRI), \\nand other medical pictures. It has been shown to be just as \\nconvincing as traditional human speciali sts in the area when it \\ncomes to accuracy. On a regular basis, Computer Vision is \\neffectively diagnosing pneumonia, cerebrum tumor’s , diabetes, Parkinson\\'s illness, malignant uterine growth, and a host of other \\nmedical issues, and the technology is getting  more advanced. With \\nthe use of best -in-class image processing technology and \\ncomputer vision methods, early identification of any potential \\ndiseases will be feasible. In this manner, treatment may be \\nadministered at an inconvenient time during the disease  or, in any \\nevent, the likelihood of their recurring is decreased [2].  \\n \\nFig 10: Cross -section of the 3D image of CT Scan and MRI [2]  \\n \\nB. Automobile:  \\n     With the expanded publicity of oneself driving autos, car \\nbusinesses are vigorously subject to Computer Vision since it is \\nintended for understanding the driving condition, including \\nidentifying impediments, people on footpaths, and conceivable \\ncrash ways. Self -driving autos are gradually advancing into the \\nmarket, with more organizations searching for imaginative \\napproaches to bring progressively electric vehicles onto the street. \\nComputer Vision innovation enables these self -driving vehicles \\'to \\nsee\\' the earth while AI calculations make the \"minds\" that help that \\nComputer Vision translate the items around the vehicle. Self -\\ndriving autos are furnished with numerous cameras to give a total \\n360-degree perspective on nature inside the scope of several \\nmeters. Tesla vehicles, for example, utilize something like 8 \\nencompasses cameras to accomplish this accomplishment. Twelve \\nultrasonic sensors for identifying hard and delicate articles out and \\nabout and a front -oriented radar that empowers the identification  \\nof different vehicles even through downpour or mist are \\nadditionally introduced to supplement the cameras. With a lot of \\ninformation being encouraged into the vehicle, a basic PC won\\'t \\nbe sufficient to deal with the inundation of data. This is the reason \\nall self -driving autos have a locally available PC with Computer \\nVision highlights made through AI. The cameras and sensors are \\nentrusted to both recognize and group protests in nature - like \\npeople on foot. The area, thickness, shape, and profundity of th e \\nitems must be considered quickly to empower the remainder of the \\ndriving framework to settle on proper choices. Every one of these \\ncalculations is just conceivable through the incorporation of AI \\nand deep neural systems, which results in highlights like the \\nperson on foot recognition [15].     \\n                      International Journal of Engineering Applied Sciences and Technology , 2021    \\n    Vol. 6, Issue 1, ISSN No. 2455 -2143, Pages 249-254 \\n                                  Published Online May 2021 in IJEAST (http://www.ijeast.com)                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n \\n253 \\n \\n \\n                                                    \\nFig 11: Tesla Car’s Vision, Source: Tesla [ 15] \\nC. Astronomy:  \\n     Our full understanding of the universe is based on photon \\nestimations, which are mostly compose d of pictures of the \\nuniverse. This opens the door to the potential of utilizing \\nComputer Vision in astronomy since our universe is so enormous, \\nand our universe\\'s lone natural rule predicts that the data gathered \\nwill be just as large. It will be impossib le for the stargazer, or for \\nanybody else, to physically contemplate this information in its \\nentirety. We can decipher all of the data in a short period of time, \\nthanks to Computer Vision. To put it another way, computer vision \\nis currently being utilized to find new planets and big bodies, with \\napplications such as exoplanet imaging, star and cosmic system \\ngrouping, and other similar tasks [3].  \\nD. Industrial:  \\n     In Industries, Computer Vision is utilized on the mechanical \\nproduction systems for checking groups, identifying harmed parts, \\nfor the examination of the completed merchandise. Here, Machine \\nVision apparatuses help in discovering infinitesimal level \\nsurrenders in items that basically can\\'t be distinguished through \\nhuman vision. In assembling under takings, perusing scanner tags \\nor QR code are fundamental as they give a one of a kind \\nrecognizable proof to an item. Perusing a great many standardized \\nidentifications in a day isn\\'t a simple errand for people; at the same \\ntime, it very well may be done e ffectively in minutes through \\nComputer Vision [ 3]. \\nIV ConvNet ARCHITECTURE  \\nConvolutional Neural Networks (CNNs) is a kind of neural \\nnetwork that has been around since the mid -90s. You\\'ll discover \\nsome more visually arresting designs in the section below [ 9]. \\nA convolutional neural network was in the process of being \\ncreated from the late 1990s to the middle of the 2010s, and it was \\nknown as LeNet during that time period. The tasks that \\nconvolutional neural networks were capable of doing grew increasingly f ascinating as an ever -increasing quantity of \\ninformation and processing power became accessible.  \\n(2).AlexNet (2012) – In 2012, Alex Krizhevsky (together with \\nothers) published AlexNet, which was a more in -depth and much \\nmore complete version of the LeNet. AlexNet was the clear winner \\nof the inaugural ImageNet Large Scale Visual Recognition \\nChallenge (ILSVRC) in 2012, outperforming the competition by \\na wide margin. This research represented a major advancement \\nover prior techniques, and the widespread use of  CNNs today may \\nbe linked back to the findings of this study.  \\nA Convolutional Network created by Matthew Zeiler and Rob \\nFergus was presented at the ILSVRC 2013 as part of the 3.ZF  Net \\n(2013) session. The ZDNet was the moniker that was given to this \\nnetwork (short for Zeiler and Fergus Net). It was feasible to make \\nimprovements to AlexNet by altering the design hyperparameters \\nused in its creation. When Szegedy and colleagues from G oogle \\npresented a Convolutional Network at the ILSVRC 2014 \\nconference, it was given the moniker \"GoogleLeNet\" (2014). This \\norganization\\'s main goal was the creation of an Inception Module \\nthat significantly decreased the number of parameters in the \\nsystem (4M, contrasted with AlexNet with 60M).  \\nIn the 2014 International Laser Scanning and Vision Research \\nConference (ILSVRC), a system that became known as the \\nVGGNet  was the first to cross the finish line. In particular, it aimed \\nat demonstrating how important it is for efficient execution to have \\na system with sufficient depth (i.e., layers). It was ResNets (2015), \\na Residual Network created by Kaiming He (and others ), that was \\nawarded sixth place in the ILSVRC 2015. ResNets (2015) was the \\nwinner of the ILSVRC 2015. Convolutional Neural Network \\nmodels such as ResNets are currently by a wide margin the best -\\nin-class models, and they will continue to be the default opti on for \\nutilizing ConvNets for the foreseeable future (as of May 2016).  \\nThe seventh source is DenseNet, which was launched in August \\n2016. A network of nodes that are closely packed together. This \\ndensely linked convolutional network, developed by Gao Huang  \\n(and others) and published recently, has each layer directly \\nconnected to every other layer in a feed -forward architecture, with \\neach layer being straightforwardly correlated with each other \\nlayer. Following the completion of five highly concentrated arti cle \\nacknowledgment benchmark assignments, the DenseNet was \\nfound to have gained substantial gains over prior best -in-class \\narchitectures, results revealed. View this video to see exactly how \\nthe Torch was carried out.  \\nV. CONCLUSION  \\n     At the beginning of  the paper, we discussed the overview of \\ndeep learning and how Neural networks in dep learning are \\ndeployed to process various inputs to gain desired outputs.  In the \\nlater part, the author has focused on Convolutional Neural \\n                      International Journal of Engineering Applied Sciences and Technology , 2021    \\n    Vol. 6, Issue 1, ISSN No. 2455 -2143, Pages 249-254 \\n                                  Published Online May 2021 in IJEAST (http://www.ijeast.com)                                                                                                                                                                                                                                                                                                                                                                                                                                      \\n \\n254 \\n \\nNetwork and explained in detai l a convolution operation, the \\nsystem architecture of CNN, and how the layers of CNN work in \\ncoordination to identify the highlights and the patterns of an \\nimage. Using these algorithms author has described how CNN can \\nbe applied in various industries. Thr ough this paper, it can be \\nconcluded that CNN has become a very powerful tool in machine \\nlearning. By providing various images as input data at the machine \\nlearning phase can facilitate the learning process faster, and the \\ndata can be deployed for multiple -output functions, which is a \\nmajor advantage of CNN. Apart from the application, the author \\nmentioned in the earlier section that CNN is now also being \\nconsidered for IoT, Commercial, and domestic security systems. \\nThus, CNN has gained a very prominent pl ace in Data Engineering \\nand still is gaining.  \\nVI REFERENCES  \\n[1] Pulkit Sharma, Analytics Vidhya, An Introductory Guide to \\nDeep Learning and Neural Networks, 22 Oct. 2018, \\nhttps://www.analyticsvidhya.com/blog/2018/10/introduction -\\nneural -networks -deep-learni ng/ \\n[2] Khan, S. A Guide to Convolutional Neural Networks for \\nComputer Vision. Morgan &amp; Claypool, 2018.  \\n[3] Verma, Shiva. “Understanding 1D and 3D Convolution Neural \\nNetwork: Keras.” Medium, Towards Data Science, 1 Oct. 2019,  \\ntowardsdatascience.com/u nderstanding -1d-and-3d-convolution -\\nneural -network -keras -9d8f76e29610.  \\n[4] Upadhyay, Yash. “Computer Vision: A Study on Different \\nCNN Architectures and Their Applications.” Medium, AlumnAI \\nAcademy, 29 Mar. 2019, \\nmedium.com/alumnaiacademy/introduction -to-computer -vision -\\n4fc2a2ba9dc  \\n[5]CS231n Convolutional Neural Networks for Visual \\nRecognition, cs231n.github.io/convolutional -networks/.  \\n[6] “Autopilot.” Tesla, Inc, www.tesla.com/autopilot.  \\n[7] Deshpande, Adit. “A Beginner\\'s Guide To Understanding \\nConvolutiona l Neural Networks.”  \\nA Beginner\\'s Guide To Understanding Convolutional Neural \\nNetworks – Adit Deshpande – Engineering at forwarding | UCLA \\nCS \\'19,  \\nadeshpande3.github.io/adeshpande3.github.io/A -Beginner\\'s -\\nGuide -To-Understanding -Convolutional -Neural -Network s/.  \\n[8] Upadhyay, Yash. “Computer Vision: A Study On Different \\nCNN Architectures and Their Applications.” Medium, AlumnAI \\nAcademy, 29 Mar. 2019, medium.com/alumnaiacademy/introduction -to-computer -vision -\\n4fc2a2ba9dc.  \\n[9] Ujjwalkarn. “An Intuitive Explanat ion of Convolutional \\nNeural Networks.” The Data Science Blog, 29 May 2017, \\nhttps://www.ujjwalkarn.me/2016/08/11/intuitive -explanation -\\nconvnets/.  \\n[10] Gibson, Adam, and Josh Patterson. “Deep Learning.” \\nO\\'Reilly | Safari, O\\'Reilly Media, Inc.,   \\nwww.oreilly .com/library/view/deep -\\nlearning/9781491924570/ch04.html  \\n[11] “What Is Deep Learning?: How It Works, Techniques &amp; \\nApplications.” How It Works, Techniques &amp; Applications - \\nMATLAB &amp; Simulink, \\nwww.mathworks.com/discovery/deep -learning.html.  \\n[12] Br ownlee, Jason. “What Is Deep Learning?” Machine \\nLearning Mastery, 31 Oct. 2019, \\nmachinelearningmastery.com/what -is-deep-learning/.  \\nView publication stats')]"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"],"metadata":{"id":"NzOZ8bTztg64","executionInfo":{"status":"ok","timestamp":1708278950725,"user_tz":-330,"elapsed":6,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["from langchain import PromptTemplate\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains.summarize import load_summarize_chain\n","from langchain.docstore.document import Document"],"metadata":{"id":"SHSzR6IZti4v","executionInfo":{"status":"ok","timestamp":1708278950725,"user_tz":-330,"elapsed":5,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["template = '''Write a concise and short summary of the following Reasearch Paper.\n","Summary: `{text}`\n","'''\n","prompt = PromptTemplate(\n","    input_variables=['text'],\n","    template=template\n",")"],"metadata":{"id":"tIwojUYKtkVs","executionInfo":{"status":"ok","timestamp":1708278951309,"user_tz":-330,"elapsed":3,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["chain = load_summarize_chain(\n","    llm,\n","    chain_type='stuff',\n","    prompt=prompt,\n","    verbose=False\n",")\n","output_summary = chain.run(docs)"],"metadata":{"id":"Ca2EEFVOtqMm","executionInfo":{"status":"ok","timestamp":1708278953444,"user_tz":-330,"elapsed":2137,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["output_summary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"id":"8oiGe3q2txrn","executionInfo":{"status":"ok","timestamp":1708278953446,"user_tz":-330,"elapsed":15,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"04667a42-9196-4178-c68c-3b242b530cb7"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The research paper discusses the application of Artificial Intelligence in Computer Vision, focusing on Convolutional Neural Networks (CNN). It explains the architecture and components of CNN, as well as its applications in various fields such as healthcare, automotive, astronomy, and industrial sectors. The paper also provides an overview of the evolution of CNN models over the years. The conclusion highlights the significance of CNN in machine learning and its growing prominence in data engineering. The paper references various sources to support the information presented.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["## Summarizing Large Documents Using Map Reduce"],"metadata":{"id":"wzFNhe-jt8ek"}},{"cell_type":"code","source":["from langchain import PromptTemplate\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains.summarize import load_summarize_chain\n","from langchain.text_splitter import RecursiveCharacterTextSplitter"],"metadata":{"id":"vUPYlf7at1D_","executionInfo":{"status":"ok","timestamp":1708278953446,"user_tz":-330,"elapsed":12,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# provide the path of  pdf file/files.\n","pdfreader = PdfReader('opencv.pdf')\n","from typing_extensions import Concatenate\n","# read text from pdf\n","text = ''\n","for i, page in enumerate(pdfreader.pages):\n","    content = page.extract_text()\n","    if content:\n","        text += content"],"metadata":{"id":"1tPGiEOXt-WL","executionInfo":{"status":"ok","timestamp":1708278954161,"user_tz":-330,"elapsed":726,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"],"metadata":{"id":"YUpXgEuWuBmB","executionInfo":{"status":"ok","timestamp":1708278954161,"user_tz":-330,"elapsed":6,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["llm.get_num_tokens(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQMlnu2AuE9E","executionInfo":{"status":"ok","timestamp":1708278954161,"user_tz":-330,"elapsed":5,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"79ec4f28-6439-4758-f272-397c3c071217"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6098"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["## Splittting the text\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=20)\n","chunks = text_splitter.create_documents([text])"],"metadata":{"id":"vBpNeHdfuGY5","executionInfo":{"status":"ok","timestamp":1708278954161,"user_tz":-330,"elapsed":4,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["len(chunks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I01LZNdMuN7W","executionInfo":{"status":"ok","timestamp":1708278954761,"user_tz":-330,"elapsed":604,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"31ec1391-6dc9-4d0e-b728-5e8d5467891f"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["chain = load_summarize_chain(\n","    llm,\n","    chain_type='map_reduce',\n","    verbose=False\n",")\n","summary = chain.run(chunks)"],"metadata":{"id":"Ze_OMKhsuP9i","executionInfo":{"status":"ok","timestamp":1708279003697,"user_tz":-330,"elapsed":48940,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["summary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"jU8iTH7KuSYq","executionInfo":{"status":"ok","timestamp":1708279003698,"user_tz":-330,"elapsed":29,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}},"outputId":"d4fc6c63-1cdf-4632-e693-4fe1ed84ce3c"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The article explores the use of artificial intelligence in computer vision, specifically focusing on Convolutional Neural Networks (CNNs) for visual recognition tasks. It discusses the importance of deep learning and neural networks in various industries such as autonomous driving, aerospace, and medical research. The author explains the structure and function of CNNs, highlighting their role in processing visual images and optimizing outputs through data-driven machine learning. The article also touches on the applications of CNNs in healthcare, self-driving cars, and other fields, emphasizing their significance in interpreting images and making decisions based on extracted data. Additionally, it discusses the evolution of CNN architecture and key developments in the field, concluding with the potential applications of CNN in IoT, commercial, and domestic security systems.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["## Map Reduce With Custom Prompts"],"metadata":{"id":"jUtZMuKhuWEF"}},{"cell_type":"code","source":["chunks_prompt=\"\"\"\n","Please summarize the given Research Paper:\n","Speech:`{text}'\n","Summary:\n","\"\"\"\n","map_prompt_template=PromptTemplate(input_variables=['text'],\n","                                    template=chunks_prompt)"],"metadata":{"id":"Q5iSD2nVuUWe","executionInfo":{"status":"ok","timestamp":1708279003698,"user_tz":-330,"elapsed":26,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["final_combine_prompt='''\n","Provide a final summary of the entire Research Paper with these important points.\n","Add business analytics and real worls use cases,\n","Start the precise summary with an introduction and provide the\n","summary in number points for the Research Paper.\n","Speech: `{text}`\n","'''\n","final_combine_prompt_template=PromptTemplate(input_variables=['text'],\n","                                             template=final_combine_prompt)"],"metadata":{"id":"1C0zSNj0uth7","executionInfo":{"status":"ok","timestamp":1708279003699,"user_tz":-330,"elapsed":27,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["summary_chain = load_summarize_chain(\n","    llm=llm,\n","    chain_type='map_reduce',\n","    map_prompt=map_prompt_template,\n","    combine_prompt=final_combine_prompt_template,\n","    verbose=False\n",")\n","output = summary_chain.run(chunks)"],"metadata":{"id":"tq1rgDSUvIoW","executionInfo":{"status":"ok","timestamp":1708279181841,"user_tz":-330,"elapsed":69694,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["output"],"metadata":{"id":"lntotmH4vLG2","executionInfo":{"status":"aborted","timestamp":1708279088504,"user_tz":-330,"elapsed":6,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Introduction:\n","# The research paper delves into the use of artificial intelligence in computer vision, specifically focusing on deep learning techniques like Convolutional Neural Networks (CNNs). It explores the basics of neural networks, the significance of deep learning in computer vision, and the diverse applications of CNNs across different industries.\n","\n","# Summary in key points:\n","# 1. The paper emphasizes the role of Convolutional Neural Networks (CNN) in processing image data and achieving desired outcomes in fields like healthcare and autonomous vehicles.\n","# 2. It underscores the importance of Computer Vision technology in revolutionizing industries and advancing with the integration of AI and deep neural networks.\n","# 3. The research paper highlights the application of CNN in various sectors such as astronomy and industrial settings, showcasing the evolution of CNN architecture from LeNet to DenseNet.\n","# 4. It concludes that CNN has emerged as a potent tool in data engineering and is increasingly being adopted in IoT, commercial, and residential security systems.\n","# 5. The paper provides valuable references for further exploration of CNN and deep learning, underscoring the significance of data-driven machine learning in decision-making processes.\n","\n","# Business analytics and real-world use cases:\n","# - CNNs are being utilized in healthcare for disease diagnosis, streamlining medical imaging processes, and improving patient outcomes.\n","# - In the automobile industry, CNNs are pivotal in the development of self-driving cars, enhancing safety and efficiency on the roads.\n","# - CNNs are also making significant strides in astronomy, aiding in the analysis of complex astronomical data and facilitating groundbreaking discoveries.\n","# - Industrial settings are leveraging CNNs for predictive maintenance, quality control, and optimizing manufacturing processes, leading to increased productivity and cost savings."],"metadata":{"id":"d-mL0knCvNoL","executionInfo":{"status":"aborted","timestamp":1708279088505,"user_tz":-330,"elapsed":7,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## RefineChain For Summarization"],"metadata":{"id":"PuP5PQgsvlSV"}},{"cell_type":"code","source":["chain = load_summarize_chain(\n","    llm=llm,\n","    chain_type='refine',\n","    verbose=True\n",")\n","output_summary = chain.run(chunks)"],"metadata":{"id":"mY6tfouFvhDt","executionInfo":{"status":"aborted","timestamp":1708279088505,"user_tz":-330,"elapsed":7,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_summary"],"metadata":{"id":"81Gqs9HMvn2S","executionInfo":{"status":"aborted","timestamp":1708279088505,"user_tz":-330,"elapsed":6,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The article delves into the use of artificial intelligence in computer vision, specifically focusing on Convolutional Neural Networks (CNNs) for visual recognition tasks. It emphasizes the significance of deep learning and neural networks in processing various types of input data. The author discusses the architecture and components of CNNs, including Convolution, which categorizes image components to assist in machine learning. The article also explores the applications of deep learning in autonomous driving, aerospace, medical research, and industrial automation. Additionally, it highlights the role of CNNs in analyzing visual images for tasks such as recommending systems, categorizing images, medical image analysis, and natural language processing. The article provides a detailed overview of how CNNs examine image content and process data to deliver desired outcomes to users. The article further discusses the application of CNNs in astronomy for discovering new planets and in industrial settings for quality control and product inspection. It also outlines the evolution of Convolutional Neural Networks through various architectures such as LeNet, AlexNet, GoogleLeNet, VGGNet, ResNets, and DenseNet, showcasing their advancements and contributions to the field of computer vision. The conclusion emphasizes the growing importance of CNNs in machine learning and their potential applications in IoT, commercial, and domestic security systems, solidifying their place in data engineering."],"metadata":{"id":"s_BU9bBxvz7Z","executionInfo":{"status":"aborted","timestamp":1708279088505,"user_tz":-330,"elapsed":6,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZBjjqgNgv0sH","executionInfo":{"status":"aborted","timestamp":1708279088506,"user_tz":-330,"elapsed":7,"user":{"displayName":"alina shaikh","userId":"07427893967666901792"}}},"execution_count":null,"outputs":[]}]}